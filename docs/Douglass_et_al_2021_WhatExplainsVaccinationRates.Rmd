---
title: What explains U.S. Covid-19 Vaccination Rates? A Machine Learning Workflow
  for Ecological Inference
output:
  html_document:
    df_print: paged
    number_sections: yes
    toc: yes
    toc_float: yes
bibliography: WhatExplainsUSCovid19VaccinationRates.bib
---

```{r, eval=T, echo=F}
knitr::opts_chunk$set(fig.width = 8, fig.height = 8, message=F, warning=F, echo=F, results=F, cache=TRUE)
```

```{r, cache=F}
fromscratch=F

#Library Loads
library(pacman)
p_load(tidyverse)
p_load(janitor)
p_load(tidylog)
p_load(stringr)
p_load(ggdag)
p_load(data.table)
p_load(sf)
p_load(glue)
p_load(scales)
#p_load(arrow)
options(tigris_use_cache = TRUE)


restartspark <- function(){
  #devtools::install_github("rstudio/sparklyr")
  #devtools::install_github("rstudio/sparklyr")
  #install.packages('sparklyr') #rolling back to the stable version
  library(sparklyr)
  #spark_available_versions()
  #spark_installed_versions()
  #spark_uninstall(version="3.0.1", hadoop_version="3.2")
  #spark_uninstall(version="2.4.3", hadoop_version="2.7")
  #oh interesting the default is spark 2.4.3 I wonder why that is
  #Error: Java 11 is only supported for Spark 3.0.0+
  #spark_install("3.0") #3.1.1 is currently the latest stable, but 3.0 is the latest available
  
  #library(geospark)
  #library(arrow)
  mem="160G"
  try({spark_disconnect(sc)})
  conf <- spark_config()
  #conf$`sparklyr.cores.local` <- 128
  #https://datasystemslab.github.io/GeoSpark/api/sql/GeoSparkSQL-Parameter/
  conf$spark.serializer <- "org.apache.spark.serializer.KryoSerializer"
  #conf$spark.kryo.registrator <- "org.datasyslab.geospark.serde.GeoSparkKryoRegistrator"
  #conf$spark.kryoserializer.buffer.max <- "2047MB" #Caused by: java.lang.IllegalArgumentException: spark.kryoserializer.buffer.max must be less than 2048 mb, got: + 10240 mb.
  #https://github.com/DataSystemsLab/GeoSpark/issues/217
  #conf$geospark.global.index <- "true"
  #conf$geospark.global.indextype <- "quadtree"
  #conf$geospark.join.gridtype <- "kdbtree"
  #conf$spark.sql.shuffle.partitions <- 1999 #https://github.com/DataSystemsLab/GeoSpark/issues/361 #setting to just under 2k so compression doesn't kick in, don't need to lower the memory footprint
  conf$spark.driver.maxResultSize <- "100G"
  conf$spark.memory.fraction <- 0.9
  conf$spark.storage.blockManagerSlaveTimeoutMs <-"6000000s" #Failed during initialize_connection: java.lang.IllegalArgumentException: requirement failed: spark.executor.heartbeatInterval should be less than or equal to spark.storage.blockManagerSlaveTimeoutMs
  conf$spark.executor.heartbeatInterval <-"6000000s"# "10000000s"
  conf$spark.network.timeout <- "6000001s"
  conf$spark.local.dir <- "/mnt/8tb_b/spark_temp/"
  conf$spark.worker.cleanup.enabled <- "true"
  conf$"sparklyr.shell.driver-memory"= mem
  conf$'spark.driver.maxResultSize' <- 0 #0 is ulimmited
  
  conf$'spark.sql.legacy.parquet.datetimeRebaseModeInRead' <- 'LEGACY'
  conf$'spark.sql.legacy.parquet.datetimeRebaseModeInWrite' <- 'LEGACY'
  
  conf$'spark.sql.execution.arrow.maxRecordsPerBatch' <- "5000000" #https://github.com/arctern-io/arctern/issues/399
  
  #Error: org.apache.spark.sql.AnalysisException: The pivot column variable_clean has more than 10000 distinct values, this could indicate an error. If this was intended, set spark.sql.pivotMaxValues to at least the number of distinct values of the pivot column.;
  conf$'spark.sql.pivotMaxValues' <- "5000000"
  
  sc <<- spark_connect(master = "local", config = conf#,
                       #version = "2.3.3" #for geospark
  ) 
}

restartspark()

```


```{r}

lhs <- spark_read_parquet(sc, path="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/data_out/lhs/lhs.parquet") %>% collect()

lhs_people_partial_10  <- quantile((lhs$people_partial_mean_perc18plus), probs = 0.1, na.rm = T,names = TRUE, type = 7) %>% round(2)
lhs_people_partial_25  <- quantile((lhs$people_partial_mean_perc18plus), probs = 0.25, na.rm = T,names = TRUE, type = 7) %>% round(2)
lhs_people_partial_50  <- quantile((lhs$people_partial_mean_perc18plus), probs = 0.50, na.rm = T,names = TRUE, type = 7) %>% round(2)
lhs_people_partial_75  <- quantile((lhs$people_partial_mean_perc18plus), probs = 0.75, na.rm = T,names = TRUE, type = 7) %>% round(2)
lhs_people_partial_90  <- quantile((lhs$people_partial_mean_perc18plus), probs = 0.9, na.rm = T,names = TRUE, type = 7) %>% round(2)

p_load(infotheo)
lhs_people_partial_entropy <- entropy(discretize(lhs$people_partial_mean_perc18plus),method="emp")
lhs_people_partial_entropy_bits <- natstobits(lhs_people_partial_entropy)

p_load(latex2exp)
p_load(ggridges)
p_load(urbnmapr)
states_sf <- get_urbn_map("states", sf = TRUE)
counties_sf <- get_urbn_map("counties", sf = TRUE) %>% mutate(fips=county_fips %>% as.numeric())
map_data <- left_join(counties_sf, lhs) 


p_county_percent_fully_vaccinated_max <-
                            ggplot( ) +
                            geom_sf(data = map_data, aes(fill = people_partial_mean_perc18plus*100)) + #long, lat, group = group,
                            geom_sf(data = states_sf, fill=NA ,  color = "black") +
                            #coord_map(projection = "albers", lat0 = 38, lat1 = 60) +
                            labs(fill = TeX("$Perc. (\\widetilde{Y}=44%)$")) +
                            scale_fill_gradient2(midpoint=44) + xlab("") + ylab("") +
                            theme(axis.title.x=element_blank(),
                            axis.text.x=element_blank(),
                            axis.ticks.x=element_blank()) +
                            theme(axis.title.y=element_blank(),
                            axis.text.y=element_blank(),
                            axis.ticks.y=element_blank())

p_state_density = map_data %>%
                  mutate(state_abbv= state_abbv %>% fct_reorder(people_partial_mean_perc18plus, .fun = median)) %>%
                  ggplot(aes(x =people_partial_mean_perc18plus*100, y = state_abbv, fill = stat(x))) +
                  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01, quantile_lines = TRUE, quantiles = 4) +
                  scale_fill_gradient2(midpoint=37) + xlab("") + ylab("") + xlim(c(10,90))


p_load(patchwork)
p_final <- (
p_state_density + theme(legend.position = "none") +
p_county_percent_fully_vaccinated_max +
  theme(legend.position = c(0.95, 0.15)))  + 
  plot_layout(widths = c(1, 5)) +
plot_annotation(
title = 'At Least Partially Vaccinated/18+ Population by County (August 13, 2021)',
subtitle = 'Mean Reported Across Vaccinetracking.us & CovidActNow',
caption = 'Douglass et al. 2021'
)
ggsave(filename="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/docs/plots/p_vacination_uptake_by_county.png", plot = p_final , height=8, width=16)

```



# Introduction

```{r, ref.label="lhs_summary_statistics", echo = FALSE}
#We can bring variables created later into the process up here for referencing in the text
```

What explains variation in COVID-19 vaccination uptake across U.S. counties? By mid-2021, only 60% of Americans have been partially vaccinated against COVID-19. Vaccination uptake varies widely between counties (percentiles 10th=`r scales::label_percent()(lhs_people_partial_10)`; 25th=`r scales::label_percent()(lhs_people_partial_25)`; 50th=`r scales::label_percent()(lhs_people_partial_50)`; 75th=`r scales::label_percent()(lhs_people_partial_75)`; 90th=`r scales::label_percent()(lhs_people_partial_90)`; entropy=`r lhs_people_partial_entropy_bits %>% round(2)` bits), and within and between states (Figure 1). Currently, there is a surplus of over 60 million vaccine doses that have been delivered but not yet administered [@cdcCOVIDDataTracker2020]. As of this writing, there have been at least 600 thousand COVID-19 deaths, cases are increasing again nationally, and forecast models expect thousands deaths in the coming weeks [@cdcCoronavirusDisease20192020]. Every percent increase in vaccine uptake has the potential to prevent thousands of deaths, tens of thousands of hospitalizations, and hundreds of thousands of infections [@bartschLivesCostsSaved2021]. Understanding the mismatch between available vaccine doses and unvaccinated communities is therefore an immediate health and welfare priority.

```{r figure1, echo=FALSE, fig.cap="A caption", out.width = '100%', results='asis'}

#You have to use results asis
knitr::include_graphics(path="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/docs/plots/p_vacination_uptake_by_county.png")

```

This article investigates possible data generating processes behind variation in U.S. vaccine uptake across counties. Our intended contributions are as follows: (1) A standardized benchmark for COVID-19 uptake that can be used to compare the performance of ours and other models; (2) A standardized cross-validation strategy for evaluating performance out of sample; (3) A synthesis of the existing literature on vaccine uptake into plausible data generating processes; (4) A high performing model that explains the majority of variation in vaccine uptake in the U.S.; and (5) Extensive ablation analysis that precisely highlights the importance of subsets of features.

The article is organized into the following sectoins. The first section provides a brief literature review of comparable vaccine uptake projects for COVID-19 in the US. The next section defines the outcome, unit of analysis, and domain. We then describe out measurement strategy for vaccine uptake, and propose a train, validation, and test strategy. 

# Current State of the Art

We organize the research on vaccine uptake along the following lines. In this section we summarize only the most proximate literature on explaining COVID-19 vaccine uptake across U.S. geographic units, listed in Table 1. In the next section discussing our outcome, we review relevant measurement projects attempting to record uptake accurately. Finally in the section theorizing possible data generating processes for vaccine uptake we summarize the extensive literature on vaccine hesitancy, vaccine supply, previous vaccnie campaigns, etc. 

```{r}

p_load(googlesheets4)
lit_review_lhs <- googlesheets4::read_sheet("https://docs.google.com/spreadsheets/d/1XGVatAyKU_oJyIW_JAuXsxw__gSm6g7ZLNfXQfqAfbE/edit?usp=sharing")
lit_review_rhs <- googlesheets4::read_sheet("https://docs.google.com/spreadsheets/d/1XGVatAyKU_oJyIW_JAuXsxw__gSm6g7ZLNfXQfqAfbE/edit#gid=870929858")
lit_review_datasets <- googlesheets4::read_sheet("https://docs.google.com/spreadsheets/d/1XGVatAyKU_oJyIW_JAuXsxw__gSm6g7ZLNfXQfqAfbE/edit#gid=1136309785")
```

```{r, results="asis"}

#Tom, or whoever, asis and or format='markdown' used to work for just putting cites directly in a tbale. I don't know why it doesn't work anymore, current theory is rnotebook doesn't like it and maybe bookdown or something else will
lit_review_lhs %>% kableExtra::kable(format = "markdown")
#require(huxtable)
#lit_review %>% as_hux %>%
#    set_caption("Hux table") 
```

The state of the art for explaining COVID-19 vaccine uptake across geographic units in the U.S. is poorly defined and incomplete. There is no accepted standard benchmark for comparing performance of competing explanations, each study picks their own subset of untis, time cut off, and data source on an ad hoc basis. With the exception of a very small literature attempting to forecast vaccine rates, this work is largely exploratory, focusing on whether a simple model places non-zero weight on a feature and reporting only in sample performance or ignoring performance all together. 

Forecasting work projects known uptake rates some number of weeks into the future [@chernyavskiyCOVID19VaccineUptake2021]. They focus on a different question, what explains change in vaccine uptake over time, and so predict future values conditional not just on features but also past known values, whereas we seek to understand what previous features prior to the start why the entire vaccine roll out was more successful in some parts of the country than others.

[@mishraCOVID19VaccineCoverage2021], predicts county level vaccine uptake using CDC data, with a multi-level linear model, fit to a hand engineered ranking indexes of 28 county measures organized into 5 themes (historic under-vaccination, sociodemographic barriers, resource-constrained healthcare system, healthcare accessibility barriers, and irregular care-seeking behavior). Their best performing model has an marginal $R^2$ of only 0.17, which while not directly comparable does illustrate the low starting baseline for accounting for uptake variation in the existing literature. [@stewartInequitiesVulnerableCommunities2021] fit multilevel models of uptake measured by COVIDcast weighted and find nonzero weights placed on COVID-19 Community Vulnerability Index but do not report performance.

The next most direct work is descriptive...


```{r, results="asis"}

#Tom, or whoever, asis and or format='markdown' used to work for just putting cites directly in a tbale. I don't know why it doesn't work anymore, current theory is rnotebook doesn't like it and maybe bookdown or something else will
lit_review_rhs %>% kableExtra::kable(format = "markdown")
#require(huxtable)
#lit_review %>% as_hux %>%
#    set_caption("Hux table") 
```




Survey studies show that COVID-19 vaccine hesitancy or intention to receive the vaccine is related to education, employment, income, demographics, psychological antecedents, COVID-19 exposure, belief of community benefits, vaccine safety concerns, state political leanings [@chuIntegratingHealthBehavior2021, @malikDeterminantsCOVID19Vaccine2020, @kwokInfluenzaVaccineUptake2021, @tramDeliberationDissentDistrust2021, @kellyPredictorsWillingnessGet]. [@truongWhatFactorsPromote2021] review 28 studies on vaccine hesitancy around Influenza H1N1 and Ebola and find a similar list of seven relevant factors: demographics (including education and employment), accessibility, personal responsibility and risk perceptions, precautionary measures taken, trust in health authorities and vaccines, the safety and efficacy of a new vaccine, and lack of information or misinformation.

[@pathakPopulationAgeIneligibleCOVID192021] estimate the geographic and ethnic distribution of the vaccine eligible population.


# Vaccine Uptake

## Outcome, Performance Metric, Unit of Analysis, and Domain 

Our outcome ($VaccineUptake$) is the number of persons at least partially vaccinated in each county ($Vaccinated$) divided by the over 18 population measured by the recent 2020 census ($Pop18+$). We choose this specific outcome instead of nearby alternatives such as fully vaccinated, or percent of eligible population, for several reasons. First, our substantive practical interest is in why some Americans who are not currently vaccinated might become vaccinated in the near future. Those that receive one dose are likely to receive the second, those that don't are at least have partially immunity, and for measurement purposes some vaccines such as Johnson & Johnson only require one dose and constitute fully vaccinated. Second, eligibility criteria is endogenous to uptake across groups first in line and in any case nearly uniform across states now. We choose the denominator of 18 plus population because it is much more accurately measured in the recent 2020 census release than 12 plus population based on extrapolations from the 2010 census and because vaccination for children 12 to 18 is still much more uncommon in the U.S.

As features, we include the datasets shown in table XXX.^[See the github repository for a full list of variables]  

We choose out of sample root mean squared error (RMSE) as our performance metric $L(\hat{VaccineUptake_{oob}}, VaccineUptake_{oob})$.

We limit our domain to the continental United States, excluding Alaska, Hawaii, and island territories because of their unique logistical constraints in vaccine distribution. Our unit of analysis is the U.S. county at a single time point, July 1, 2021. Counties are the smallest dissagregation available for the entire U.S. as zip-code level data is available for a few states, and cross-unit measurement error encountered already at the county level make us dubious about zooming in with current data.



```{r, results="asis"}

#Tom, or whoever, asis and or format='markdown' used to work for just putting cites directly in a tbale. I don't know why it doesn't work anymore, current theory is rnotebook doesn't like it and maybe bookdown or something else will
lit_review_lhs %>% kableExtra::kable(format = "markdown")
#require(huxtable)
#lit_review %>% as_hux %>%
#    set_caption("Hux table") 
```





## Measurement Strategy

Our measurement strategy is based on official statistics compiled by county and state health departments, further aggregated into a national panel by third parties. We consider four national panels compiled by the CDC [@COVID19VaccinationsUnited], Vaccinetracking.us [@Data], CovidActNow [@DataDefinitionsCovid], and the USA Today News Network. For a random sample of counties and a number outliers, we compared these national panels to direct reporting on state and county websites. We concluded that there are sources of measurement error (see Appendix 1), that necessitate aggregating across panels, taking the mean uptake for each county ($c$) reported, $Y_c=mean_c(Vaccinetracking.us_c, CovidActNow_c)$. We use $USAToday_c$ which tracks only completed vaccination as a check for outliers, and we exclude $CDC_c$ entirely do to extraordinary missingness and underreporting. 

There are at least three main measurement error concerns that we are aware of. The first is that states/counties either fail to report or national panels fail to pull correct counts for a non-random subset of states and counties. This error was most pronounced in the CDC panel and make it inappropriate for this kind of analysis, despite being the most relied upon source in the literature. Second, there is reporting error by state that fails to correctly record home county of the individual, either missing the information entirely or incorrectly attributing it to the county where the vaccine was administered. Of the panels, only CovidActNow explicitly attempts to correct for entirely missing county records due to policy in a handful of states. Together, we find the biggest threat to measurement to come from under-reporting rather than over-reporting. The most likely possible negative consequences of our decision to take the maximum across sources is to attenuate variation between neighboring counties and to replace ad-hoc measurement failure with ad-hoc imputation by CovidActNow for a handful of states. We find both risks greatly preferable to the known problems with the data as is, and we mitigate them in our modeling strategy. The third is county data do not consistently take into account doses administered through federal sources, e.g. Department of Defense, Veterans Affairs, Homeland Security, etc. Here too we attempt to mitigate this with features that measure military and veteran presence as well as in the case of the VA, counts of doses administered by installation in a given county.


<!-- https://www.washingtonpost.com/graphics/2020/health/covid-vaccine-states-distribution-doses/ -->
<!-- Doses are also being distributed to the Defense Department, State Department, Department of Veterans Affairs, Federal Bureau of Prisons, Department of Homeland Security and Indian Health Service. On Feb. 19, the CDC altered its reporting of doses being administered by the Department of Defense, Bureau of Prisons, Indian Health Service and Veteran’s Health Administration. The CDC added the shots given by those agencies to the states where the shots had been given. It didn’t change the national total, but it added two million shots to various state totals. The shots had been administered over two-and-a-half months, but they were all reported on Feb. 19, causing large one-day increases in Virginia, New Mexico, North Dakota, Texas, Massachusetts, Connecticut and other states. -->

## Train, Validation, and Test Strategy

Our goal is to decompose observed vaccine uptake into an unmeasured error component and a measured data generating processes orthogonal to the error component whose contribution comes only through the features. We further want to evaluate many possible data generating processes. These goals are challenging for observational social science data and require specific inferential strategies. 

One challenge is that our data are a one-time collection, we cannot inductively form hypotheses and then requisition a new batch of data from the same data generating process (DGP) to evaluate them. We therefore need to partition the data in hand into a training split where we fit models, a validation split where we refine those models inductively, and a final test split where we evaluate our final decisions and ideas. Our confidence in a possible DGP being the true one is in how well it generalizes to new unseen draws from the same process. From an information theoretic perspective, we desire a compact representation that removes idiosyncratic information leaving only information that generalizes to any draws from the DGP. This is in contrast to the typical practice in the social sciences of making strong theoretical assumptions about the DGP and then providing evidence in the form a nonzero weight placed on a feature by a model fit to in sample data. That practice is inappropriate here because we desire to explain variation in vaccine uptake, we don't have strong prior beliefs on the role of any single feature, a non zero weights assigned by a model is not strong evidence that a particular feature is important [@bzdokInferencePredictionDiverge2020], repeated testing of the same in sample data quickly diminishes information learned by each of that kind of test [@thompsonDatasetDecayProblem2020a], considering more than a few features quickly diminishes the intended interpretation of those weights [@achenLetPutGarbageCan2005], and any sufficiently flexible functional form makes simply memorizing a dataset trivial.

A second challenge is that our data are not independent and identically distributed (IID) draws from the same DGP, which reduces the amount of unique information available and makes selection of splits difficult [@robertsCrossvalidationStrategiesData2017]. Our county observations are administratively correlated at the state level at a minimum through vaccine distribution strategies and data reporting mechanisms. Our county observations are at a minimum spatially correlated through transportation logistics, flow of vaccine seekers from one county to another, and reporting error assigning some vaccinations to the location it was administered and not the home address of the person. Training on a county and then testing on its immediate neighbor may end up memorizing local geographic patterns rather than the actual role of features.

Our train, validation, and test strategy is based on consensus features within nested cross-validation [@parvandehConsensusFeaturesNested2020]. We split our county data along state lines into 5 large geographically contiguous regions shown in Figure 1. We choose regions by hierarchically clustering states based on total human interstate travel between each pair of states in 2019 measured by cell phone locations collected by SafeGraph [@kangMultiscaleDynamicHuman2020].^[We hierarchically cluster interstate trips using Ward's distance, and cut the dendrogram at 6 clusters. New England presents as a unique cluster but has only 45 counties and so we collapse it the North East folds resulting in 5 total.] An outer loop withholds a region as a test set which is only used for making out of sample predictions, never training. An inner loop fits a model 4 times in 4 folds cross-validation, each iteration training on 3 regions and predicting on 1 validation region. This cross-validation step allows us to choose model hyper-parameters, most important of which is which features to include in the final model.



```{r figure 2, fig.width = 6, fig.height = 4, result=T}

states_sf_tigris_continental <- readRDS( "/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/data_out/states_sf_tigris_continental.Rds")

p_test_folds <- states_sf_tigris_continental  %>% mutate(fold=fold %>% as.factor()) %>%
  ggplot(aes(fill = fold  )) +
  geom_sf() + 
  ggtitle("5 Test Fold Splits") #+ xlim(c(NA,-50)) + ylim(c(20,50))
#p_test_folds

ggsave(filename="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/docs/plots/p_test_folds.pdf", plot = p_test_folds , height=8, width=16)

```


```{r figure2, echo=FALSE, fig.cap="A caption", out.width = '50%', results='asis'}

#I don't know
#knitr::include_graphics(path="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/docs/plots/p_test_folds.pdf")

p_test_folds

```


Our feature selection strategy proceeds in three steps. First, our modelling technology is gradient boosted trees (GTB) which is a greedy algorithm that iteratively includes features until a condition is met. This immediately prunes most features that are never selected in any of the folds. Second, we subset to consensus features that are chosen in at least 2 of the 4 CV folds further reducing to just features that found broad geographic support. Our final step is to drop features which do not improve out of sample CV performance. Directly checking the performance of every subset is intractable ($k!$ many possible subsets), and so we rank order features by suspected importance and test the $k$ number of cumulative sets. Our measure of importance is the LossSHAP value which is the change in residuals on the hold out validation set when we subtract off the marginal contribution (SHAP value) of each feature [@lundbergLocalExplanationsGlobal2020]. This criteria is most directly relevant to the outcome we care about, performance on unseen out of sample data, and allows for the possibility of negative importance where a feature leads to over-fitting and doesn't generalize.

We then finalize our feature and hyper parameter selection, fit a single model to the full data of all 4 training folds, and make a single out of sample prediction on the remaining 1 test fold. By doing this full procedure separately for each of the 5 folds, we produce full out of bag predictions for every county in the U.S. The results can be directly interpreted as the amount of out of sample performance in predicting vaccine uptake that can be purchased with a given set of features and fixed regularization budget. How useful a feature is can be interpreted directly in terms of how much unique performance it buys, and its role in the DGP can be interrogated via the functional form chosen across all of the individual models.


```{r algorithm1, echo=F, tidy=FALSE, eval=FALSE, highlight=FALSE }
procedure ConsensusFeaturesCV( Y, X, folds)
  
  for i in folds
    remaining_folds <- folds - i
    m = |folds|/2
    for j in remaining_folds
      training_folds <- remaining_folds - j
      F_j <- GradientBoostedTrees(Y|X, training_folds)
      selected_features_j <- features where importance_scores(F_j)>0
    features_consensus = #(features ∈ features_used_j) >= m
    
      
    
  
```


## Identification Strategy, Placebo Comparisons, and Feature Evaluation

Our research design is purely observational, we make no claim to exogeneity, nor do we believe that even our large number of features 'control' for relevant confounding. Instead, our strategy is an information theoretic one, to propose and rigorously evaluate compact representations that potentially generalize to more draws from the same data generating process. We supplement this with placebo analysis to determine to what degree a representation is uniquely good for our outcome of vaccine uptake relative to other similar but unrelated outcomes [@eggersPlaceboTestsCausal2021]. We therefore consider a feature 'important' if it meets the following criteria (1) it greatly improves the ability to predict the outcome in out of sample observations (2) that improvement is unique to that feature, and cannot be easily reconstruct through other features that do not share the same theoretical interpretation, and (3) that improvement is unique to our outcome. Features that meet all three criteria suggest further research using either more appropriate individual level data or an experimental design with plausible causal identification. Features that do not may still be part of the true data generating processes, but were not distinguished in the county level data available here.

# Potential Data Generating Processes of Vaccine Uptake

## Historical Background

COVID-19 vaccinations began in the U.S. on December 14, 2020 [@affairsaspaCOVID19VaccineDistribution2020]. The U.S. Food and Drug Administration issued an emergency use authorization (EUA) for persons 16 years or older in December, 2020 which it expanded to 12 and older in May, 2021. The majority of vaccinations given in the U.S. are the two dose sequence by Pfizer, followed by Moderna, and then to a much smaller degree the single dose Johnson and Johnson which was briefly paused in April, 2021. The number of vaccinations given per day increased nearly monotonically before peaking nationally in mid-April at over 3 million doses per day, and then declining to a nadir of about half a million doses per day in July. With the advent of the SARS-CoV-2 Delta variant and a fourth wave of cases in the U.S. vaccination rates are beginning to increase again albeit much more slowly. 

## Potential Data Generating Process and Feature Proposals

```{r, eval=F}

library(huxtable)
library(tidyverse)


#install.packages("huxtable")
library(stringi)
rhs_codebook_total_coded <- read.csv(file="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/rhs_codebook_total_coded.csv") %>% 
  janitor::clean_names() %>% #for these columns
  mutate(variable_clean = variable %>% janitor::make_clean_names()  ) 

rhs_codebook_total_coded <- rhs_codebook_total_coded %>% 
  dplyr::select(-variable_short, -variable_short_group, -dataset,-description_stemmed) %>%
  ####
  filter(!warning_dv %in% 1) #We're excluding warning DV from this

dim(rhs_codebook_total_coded)
rhs_codebook_total_coded %>% dplyr::select(-variable, -variable_clean) %>% colSums(na.rm=T) %>% sort()
variable_groups <- rhs_codebook_total_coded %>% dplyr::select(-variable, -variable_clean) %>% colSums(na.rm=T) %>% sort() %>% names()
variable_groups <- variable_groups[!variable_groups %in% c("warning_dv","va_vaccinations")] #va vvaccinations isn't in xtable right onw and that's fine

x_all <- readRDS("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/data_out/x_train.Rds")
x_all_variables <- data.frame(variables=colnames(x_all))
rhs_codebook_total_coded <- rhs_codebook_total_coded %>% filter(variable_clean %in% colnames(x_all)) #there's two random x and x_2 from the google sheet

x_all_255 <- x_all
x_all[!is.finite(x_all_255)] <- NA
not_missingness <- colSums( !is.na(x_all) ) # / nrow(rhs_combined_wide)
nonzero <- colSums( x_all>0 , na.rm = T)
both <- colSums( !is.na(x_all) & x_all>0  , na.rm = T)
table(not_missingness<500) #there are 6k that have fewer than 500 obs
table(nonzero<500) #there are 6k that have fewer than 500 obs

table(not_missingness>500 & nonzero>500)
x_all <- x_all[,not_missingness>500 & nonzero>500]  #lightgbm requires both a certain amount of nonmissingness and a certain amount of variation. Kill any variable with less than 500 obs or less than 500 nonzero obs
dim(x_all)

rhs_codebook_total_coded <- rhs_codebook_total_coded %>% filter(variable_clean %in% colnames(x_all))

```



```{r, eval=F}

#We propose a data generating process for reported vaccine uptake that is a function of vaccine demand, vaccine supply, and institutional reporting mechanisms. We consider `r comma_format()(x_all %>% ncol())` features, drawn from `r rhs_codebook_total_coded$dataset %>% unique %>% length` data sets, which we organize roughly into `r rhs_codebook_total_coded %>% ncol()-3` non-exclusive topics.

temp <- rhs_codebook_total_coded %>% dplyr::select(-variable,-variable_clean) %>% group_by(dataset) %>% dplyr::summarise_all(max) %>% t()
temp %>% write.csv("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/rhs_topics_vs_datasets.csv")

```


## Supply Side

Before May 10, 2021 vaccines were allocated in a tiered system allocating lots across states (based on their total adult population) and federal agencies, who in turn chose health departments, hospitals, and retail pharmacies [@COVID19VaccineAllocations]. After May 10, individual locations could order vaccines directly from the supplier. States issued tiered eligibility schedules that prioritized elderly, healthcare workers, essential workers, etc. States and cities further prioritized demographic and economic groups sometimes at the leve of individual zip codes [@schmidtEquitableAllocationCOVID192021].


We consider a data generating process for reported vaccinations that is a function of institutional reporting mechanisms, vaccine supply, and vaccine demand. Vaccine demand is defined here as the number of vaccines that would be administered given unconstrained supply. When supply is constrained in any way, or imperfectly measured, then demand is only partially observed to be at least as much as the given supply but possibly much higher. Likewise, vaccine supply is defined here as the number of vaccines that would be administered given unconstrained demand. With perfect demand and measurement, any unused vaccines provide an upper bound on possible demand. Institutional reporting mechanisms are the process by which actual vaccine uptake is mapped into publicly reported records. As demonstrated above, institutional measurement error of health outcomes has systematic nonrandom sources of error. In some cases those systematic components may be an even larger part of the data generating process than the underlying empirical data generating process we actually care about.

Age elgibility leads to major differences [@pathakPopulationAgeIneligibleCOVID192021]


idiosyncratic state policies
religious exemption
https://www.tennessean.com/story/news/politics/2021/03/31/covid-19-vaccination-religious-exemptions-during-public-health-crisis-advance-senate/4825721001/
Parental exemption for teenagers
https://www.tennessean.com/story/news/health/2021/07/12/tennessee-fires-top-vaccine-official-covid-19-shows-new-spread/7928699002/

VaxMap 2.0 Number of facilities and driving distance to a facility [@zotero-36198]


## Demmand Side

Vaccinations per day increased week on week, peaking to average of 3 million per day in early April, and now tapering to about half a million per day.

The most proximate measure of demand available is survey self reported desire to receive a vaccine. The COVID-19 Trends and Impact Survey (CTIS) run by the Delphi group at Carnegie Mellon in partnership with Facebook

[@barkayWeightsMethodologyBrief2020] We propose to measure demand most directly with survey questions of self reported desire for a vaccination.

@bradleyAreWeThere2021 argue that the Delphi-facebook and Census Household Pulse surveys are biased compared to CDC estimates and overconfident because of their sample size  (pre-print).

https://aspe.hhs.gov/pdf-report/vaccine-hesitancy

The most proximate measure of demand available is survey self reported desire to receive a vaccine. COVID-19 Trends and Impact Survey (CTIS) run by the Delphi group at Carnegie Mellon [@barkayWeightsMethodologyBrief2020]
We propose to measure demand most directly with survey questions of self reported desire for a vaccination. 


typically referred to as vaccine hesitancy,

[@pittsHealthLiteracyCommon2021]

https://www.va.gov/vetdata/veteran_population.asp
Vertans per county
https://www.va.gov/vetdata/veteran_population.asp






Download Options
Covid-19 Vaccination Provider Locations in the United States

# Results


```{r, echo=F, warnings=F, results=F, messages=F}

x_all <- readRDS("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/data_out/x_train.Rds")
#dim(x_all)
x_all[!is.finite(x_all)] <- NA
not_missingness <- colSums( !is.na(x_all) ) # / nrow(rhs_combined_wide)
nonzero <- colSums( x_all>0 , na.rm = T)
both <- colSums( !is.na(x_all) & x_all>0  , na.rm = T)
table(not_missingness<200) #there are 6k that have fewer than 500 obs
table(nonzero<200) #there are 6k that have fewer than 500 obs
table(both<200) #there are 6k that have fewer than 500 obs
x_all <- x_all[,both>500]

rhs_codebook_total_coded <- spark_read_parquet(sc, path="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/data_out/rhs_codebook_spark/") %>% collect() #it crashes if you use both arrow and spark
rhs_codebook_total_coded <- rhs_codebook_total_coded %>% filter(!category_warning_dv %in% 1) #We're excluding warning DV from this
dim(rhs_codebook_total_coded)
rhs_codebook_total_coded <- rhs_codebook_total_coded %>% filter(variable_clean_255 %in% colnames(x_all))
rhs_codebook_total_coded %>% dplyr::select(starts_with("category")) %>% colSums(na.rm=T) %>% sort()
variable_groups <- rhs_codebook_total_coded %>% dplyr::select(starts_with("category")) %>% colSums(na.rm=T) %>% sort() %>% names()
variable_groups <- variable_groups[!variable_groups %in% c("category_warning_dv","category_va_vaccinations")] #va vvaccinations isn't in xtable right onw and that's fine
x_all_variables <- data.frame(variables=colnames(x_all))

dim(rhs_codebook_total_coded) 
number_features <- rhs_codebook_total_coded %>% select(starts_with("category_")) %>% summarise_all(sum) %>% t() %>% as.data.frame() %>% rownames_to_column(var = "ablation") %>% rename(features=V1) %>% 
                  add_row(ablation = "category_withold_nothing", features = nrow(rhs_codebook_total_coded))

yid_test_include <- spark_read_parquet(sc, name="yid_test_include", path="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/results_include/performance/" ,memory=F) %>% collect() 
yid_test_include_shuffled <- spark_read_parquet(sc, name="yid_test_include", path="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/results_include_shuffled/performance/" ,memory=F) %>% collect() 


yid_test_exclude <- spark_read_parquet(sc, name="yid_test_exclude", path="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/results_exclude/performance/" ,memory=F) %>% collect()
yid_test_cumulative <- spark_read_parquet(sc, name="yid_test_cumulative", path="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/results_exclude_cumulative/performance/" ,memory=F) %>% collect()

null_intercept <- yid_test_include %>% collect() %>% dplyr::select(fold, y_share18plus)

null_intercept <- null_intercept %>% left_join(
  bind_rows(
    null_intercept %>% filter(fold!=1) %>% summarise(y_hat_null_intercept=y_share18plus %>% mean()) %>% mutate(fold=1),
    null_intercept %>% filter(fold!=2) %>% summarise(y_hat_null_intercept=y_share18plus %>% mean()) %>% mutate(fold=2),
    null_intercept %>% filter(fold!=3) %>% summarise(y_hat_null_intercept=y_share18plus %>% mean()) %>% mutate(fold=3),
    null_intercept %>% filter(fold!=4) %>% summarise(y_hat_null_intercept=y_share18plus %>% mean()) %>% mutate(fold=4),
    null_intercept %>% filter(fold!=5) %>% summarise(y_hat_null_intercept=y_share18plus %>% mean()) %>% mutate(fold=5)
  )
)

performance_null <- null_intercept %>% summarize(rmse_null_intercept=Metrics::rmse(y_hat_null_intercept, y_share18plus), mae_null_intercept=Metrics::mae(y_hat_null_intercept, y_share18plus))  %>% mutate(ablation="null_intercept")


performance_include_shuffled <- yid_test_include_shuffled %>% collect() %>% group_by(ablation) %>% summarize(rmse_include=Metrics::rmse(y_hat_test_pruned_optimized, y_share18plus), mae_include=Metrics::mae(y_hat_test_pruned_optimized, y_share18plus))  

performance_include_seed <- yid_test_include %>% collect() %>%
                            group_by(ablation,seed) %>% summarize(rmse_include=Metrics::rmse(y_hat_test_pruned_optimized, y_share18plus), mae_include=Metrics::mae(y_hat_test_pruned_optimized, y_share18plus))  

performance_exclude <- yid_test_exclude %>% collect() %>% group_by(ablation) %>% summarize(rmse_exclude=Metrics::rmse(y_hat_test_pruned_optimized, y_share18plus), mae_exclude=Metrics::mae(y_hat_test_pruned_optimized, y_share18plus))  

performance_exclude_cumulative <- yid_test_cumulative %>% collect() %>% 
                                  group_by(ablation) %>%
                                  summarize(rmse_exclude_cumulative=Metrics::rmse(y_hat_test_pruned_optimized, y_share18plus), mae_exclude_cumulative=Metrics::mae(y_hat_test_pruned_optimized, y_share18plus))  

performance_all <- performance_exclude %>% filter(ablation=="keep_category_withold_nothing") %>% dplyr::select(ablation,rmse_all_vars=rmse_exclude)

results <-  performance_null  %>% 
            full_join(performance_all) %>%
            full_join(performance_include %>%  mutate(ablation=ablation %>% str_replace("keep_","")) ) %>%
            full_join(performance_exclude %>% 
                        mutate(ablation=ablation %>% str_replace("keep_","")) ) %>% 
            full_join(performance_exclude_cumulative %>%
              mutate(ablation=ablation %>% str_replace("exclude_","") ) ) %>% 
              full_join(number_features) %>% 
              arrange(rmse_exclude %>% desc() ) %>% 

              mutate(rmse_null_intercept=max(rmse_null_intercept, na.rm=T)) %>%
              mutate(rmse_all_vars=max(rmse_all_vars, na.rm=T)) %>%
  
              mutate(mae_null_intercept=max(mae_null_intercept, na.rm=T)) %>%
              mutate(rmse_include_percbasline= round( 1 -  rmse_include/rmse_null_intercept, 4 ) * -1 ) %>%
              mutate(rmse_exclude_percbasline= round( 1 - rmse_exclude/rmse_all_vars , 4 ) * -1 ) %>%
              mutate(rmse_exclude_cumulative_percbasline= round( 1 - (rmse_exclude_cumulative/rmse_null_intercept) , 4) * -1 ) %>%
              mutate(rmse_include= round(rmse_include*100,2 )) %>%
              mutate(rmse_exclude= round(rmse_exclude*100,2 )) %>%
              mutate(rmse_exclude_cumulative= round(rmse_exclude_cumulative*100,2 ))

                
#results %>% view()

results_df <- results  %>%
              mutate(ablation=ablation %>% str_replace("category_","") ) %>%
              filter(ablation!="keep_withold_nothing") %>%
              dplyr::select(category=ablation, features=features, rmse_include, rmse_include_percbasline, rmse_exclude, rmse_exclude_percbasline, rmse_exclude_cumulative, rmse_exclude_cumulative_percbasline)

#install.packages("huxtable")
library(huxtable)
results_ht <- results_df %>% 
  filter(!category %in% c('null_intercept','va_vaccinations','warning_dv')) %>%
                 as_hux() %>%
               set_number_format(col=c(4,6,8), value= fmt_percent(1)) %>% 
  set_background_color(evens, everywhere, "grey80") 
  #set_background_color(odds, everywhere, "grey90") #%>% 
  #set_all_borders(brdr(0.4, "solid", "white")) %>% 
  #set_outer_padding(4)
results_ht[1,] <- c('Category','Count','RMSE','Δ vs. Null','RMSE','Δ vs. All','RMSE','Δ vs. Null')

results_ht_final <- results_ht  %>% 
  #Doing this here just so it's simpler when we start adding rows later
  set_bold(which((results_ht[,3] %>% as.matrix() %>% as.numeric())== min(results_ht[,3] %>% as.matrix() %>% as.numeric(), na.rm=T)), 3:4) %>%  
  set_bold(which((results_ht[,5] %>% as.matrix() %>% as.numeric())== max(results_ht[,5] %>% as.matrix() %>% as.numeric(), na.rm=T)), 5:6)  %>% 
  set_bold(which((results_ht[,7] %>% as.matrix() %>% as.numeric())== min(results_ht[,7] %>% as.matrix() %>% as.numeric(), na.rm=T)), 7:8) %>% 
  theme_compact()  %>% 

  insert_row("Features", "", "Only this Category", "", "All but this Category","","Cumulatively Remove Categories", "", after = 0) %>% 
  merge_cells(1, 1:2) %>% 
  merge_cells(1, 3:4) %>% 
  merge_cells(1, 5:6) %>% 
  merge_cells(1, 7:8) %>%
 #set_align(1, everywhere, "center") %>%
  #insert_row("County Vaccine Uptake Predictive Performance", "", "", "", "","","", "", after = 0) %>% 
  #merge_cells(1, 1:8) %>% 
  #set_align(1, everywhere, "center") %>%
  #theme_basic()  %>%
  set_header_rows(1:2, TRUE) %>% 
  style_headers(bold = TRUE, text_color = "black") %>% 
  set_caption("County Vaccine Uptake Predictive Performance by Inclusion/Exclusion of Groups of Features") %>% 

  set_right_border(row=1:nrow(results_ht)+1, col=2) %>% 
  set_right_border(row=1:nrow(results_ht)+1, col=4) %>% 
  set_right_border(row=1:nrow(results_ht)+1, col=6) 
  #insert_row( "Features", fill = "", colspan = 1:2) %>% insert_row( "Cumulative Exclusion", fill = "", colspan = 3:4) 

```

```{r, eval=F, results=T}
#sudo apt-get install --reinstall texlive-base
#sudo apt -y install texlive-science
#results_ht %>% quick_pdf(file="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/docs/tables/results_ht.pdf", open = F)
#results_ht %>% quick_latex(file="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/docs/tables/results_ht.tex", open = F)


```

We start broadly, considering the role of large non-mutually exclusive categories of features that share an intended substantive concept. We provide three views on the importance of each category of features. In each case, we evaluate features in terms of their impact on out of sample performance, reported here as RMSE and annotated with percent reduction in error from a null intercept only baseline, which has a RMSE of 11.3% and a MEA of 9%. For example, our best performing model/set of features has a RMSE of 6.74 which is a -40.5% reduction in predictive error from the baseline.

Our first measure of feature importance is predictive power of a model with access to only features from that category. Here, self reported attitudes towards global warming and solutions towards global warming provide the most direct information (RMSE 8.11, -28.4%). Alone, categories of features vary meaningfully in how much information they provide from a great deal, voting and masking behavior, to hardly any family structure vaccine supply. Our second measure of importance is how much unique information a category of features provides, measured as the change in predictive power of a model with access to every feature but those from that category. Here, model performance degrades the most when voting behavior is withheld (RMSE 7.34, -35.2%). Unlike before, variation in the importance across features is much weaker with many features providing redundant information that can be used to reconstruct the others, a difference in only -4.4% reduction in error from best to worst performance. While global warming beliefs held the most direct information, witholding them and keep all others barely impacts the model, as it can be reconstructed from other features like education and voting behavior. Lastly, we rank order categories of features from most unique to least unique information and cumulatively remove least unique (redundant) features. We find that not only does model performance not degrade, it improves, peaking when we exclude 6 categories of features, marriage, foreign born, covid, global warming, health conditions, and citizenship. Removing access to these features improves model fit, reduces over-fitting, and removing any more than these starts to degrade model performance.



```{r, results='markup'}

#Note this table currently has holes in it because 5 categories completely overlapped at least one other category and so couldn't be evaluted in isoaltion.

pal <- function(x, low='#8b0000', mid='#000000', high='#013220', middle=0) {
  f_neg <- scales::col_numeric(
    palette = c( low, mid),
    domain = c(  min(x, na.rm=T), middle)
  )
  f_pos <- scales::col_numeric(
    palette = c(mid, high),
    domain = c(middle, max(x, na.rm=T))
  )
  ifelse(x < middle, f_neg(x), f_pos(x))
}


by_colorspace_rex <- function (low='#8b0000', mid='#000000', high='#013220', middle=0, range = NULL, na_color = NA, ignore_na = TRUE, colwise = FALSE) 
{
    #assert_package("by_colorspace", "scales")
    #palette <- c(...)
    #assert_that(is.flag(ignore_na), is.flag(colwise))
    #cn_fn <- scales::col_numeric(palette, domain = range, na.color = na_color)
    wrapped_cn_fn <- function(x) pal(suppressWarnings(as.numeric(x)), low, mid, high,middle) #cn_fn(suppressWarnings(as.numeric(x)))
    wrapped_col_numeric <- if (colwise) {
        function(x) apply(x, 2, wrapped_cn_fn)
    }
    else {
        wrapped_cn_fn
    }
    by_function(wrapped_col_numeric, ignore_na = ignore_na)
}


color_low <-  '#228B22' #'#00FF00'
color_black <- '#000000'
color_high <- '#FF0000'
options(huxtable.knit_print_df = T)
results_ht_final %>%
  map_text_color(3:nrow(results_ht_final), 3, by_colorspace_rex(low=color_low , mid=color_black, high=color_high, middle=results_ht_final[,3] %>% unlist() %>% as.numeric() %>% mean(na.rm=T), colwise = TRUE) ) %>%
  map_text_color(3:nrow(results_ht_final), 4, by_colorspace_rex(low=color_low , mid=color_black, high=color_high, middle=results_ht_final[,4] %>% unlist() %>% as.numeric() %>% mean(na.rm=T), colwise = TRUE) ) %>%

  map_text_color(3:nrow(results_ht_final), 5,
                 by_colorspace_rex(low=color_low , mid=color_black, high=color_high ,
                                   middle=(results_ht_final[,5] %>% unlist())[which( results_ht_final[,6] %>% unlist() %>% as.numeric()==0 )] %>% as.numeric(), colwise = TRUE) ) %>%
  map_text_color(3:nrow(results_ht_final), 6, by_colorspace_rex(low=color_low, mid=color_black, high=color_high, middle=0, colwise = TRUE) ) %>%

  map_text_color(3:nrow(results_ht_final), 7, by_colorspace_rex(low=color_low , mid=color_black, high=color_high , middle=results_ht_final[,7] %>% unlist() %>% as.numeric() %>% mean(na.rm=T), colwise = TRUE) ) %>%
  map_text_color(3:nrow(results_ht_final), 8, by_colorspace_rex(low=color_low , mid=color_black, high=color_high, middle=results_ht_final[,8] %>% unlist() %>% as.numeric() %>% mean(na.rm=T), colwise = TRUE) ) 
  
    
  #map_text_color(3:nrow(results_ht_final), 5:6, by_colorspace(low="darkred", mid="black", high="darkgreen", colwise = TRUE) )

```


```{r , include=knitr::is_latex_output()}
#You have to use results asis
#knitr::include_graphics(path=normalizePath("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/docs/tables/results_ht.pdf"), dpi = NA, error = FALSE)
#print_latex(results_ht)
```

```{r, cache=F}


restartspark()
treeshap_all <- spark_read_parquet(sc, name="treeshap_all",path="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/results_exclude_cumulative/shap" ,memory=F) 
sdf_nrow(treeshap_all) #19257958
treeshap_all %>% head()

treeshap_top <- treeshap_all %>% filter(ablation=="exclude_category_transportation") #%>% dplyr::select(-starts_with("category_")) %>%
                 #collect()
sdf_nrow(treeshap_top)


treeshap_interactions <- spark_read_parquet(sc, name="treeshap_interactions",path="/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/results_exclude_cumulative/shap_interactions/" ,memory=F) 
sdf_nrow(treeshap_interactions) #140,600,572

#Top interactions
treeshap_interactions_summarized_rank <- treeshap_interactions %>% 
                                          filter(ablation=="exclude_category_transportation")  %>%
                                          filter(variable_a!=variable_b) %>%
                                          group_by(variable_a,variable_b) %>% 
                                          summarise(shap_total=sum(abs(shap), na.rm=T)) %>%
                                          filter(shap_total>0) %>%
                                          collect()

treeshap_interactions_summarized_rank %>% arrange(desc(shap_total)) %>% filter(!duplicated(variable_a))


treeshap_interactions_summarized <- treeshap_interactions %>% 
                                    filter(ablation=="exclude_category_transportation") %>%
                                    mutate(covariate_value_a=covariate_value_a %>% round(2)) %>% mutate(covariate_value_b=covariate_value_b %>% round(2)) %>%
                                    group_by(variable_a,variable_b, covariate_value_a, covariate_value_b) %>% 
                                    summarise(shap=mean(shap, na.rm=T)) 
sdf_nrow(treeshap_interactions_summarized) #18,649,580

#4 causes the first error, 5 too, 6 too

number_features <- treeshap_top %>%
                   dplyr::select(ablation, test_fold,variable) %>%
                   sdf_distinct() %>%
                   count(ablation, test_fold) %>%
                   collect() %>%
                   group_by(ablation) %>%
                   summarise(feature_count_min=min(n), feature_count_mean=mean(n), feature_count_max=max(n))

folds_chosen <- treeshap_top %>%
                   dplyr::select(ablation, test_fold,variable) %>%
                   sdf_distinct() %>%
                   count(variable) %>%
                   collect() %>% 
                   arrange(n %>% desc())

shap_total <- treeshap_top %>%
               mutate(total_shap=sum(abs(shap))) %>%
               dplyr::select(variable,total_shap,shap) %>%
               group_by(variable,total_shap) %>%
               summarise(shap=sum(abs(shap))) %>%
               mutate(shap_percent=shap/total_shap) %>%
               arrange(shap %>% desc()) %>% collect()


```


```{r}

library(quantreg)
for(i in 1:length(shap_total$variable[round(shap_total$shap>0)]) ){
  
  var=shap_total$variable[i]
  temp <- treeshap_top %>% 
          dplyr::filter(variable==var) %>% 
          dplyr::select(covariate_value,shap) %>%
          collect()
  
  form= formula(shap ~ qss(covariate_value_scaled, lambda = 0.1))
  temp1 <- temp %>% 
           mutate(covariate_value_scaled= scale(covariate_value )[,1])
  suppressWarnings({ 
    model_50 <- rqss(formula=form, tau = 0.5, data = temp1 %>% na.omit() )
    temp1$median_50 <- NA
    temp1$median_50[!is.na(temp1$covariate_value_scaled)] <- predict(model_50, newdata=temp1)
    
    model_05 <- rqss(formula=form, tau = 0.05, data = temp1 %>% na.omit() )
    temp1$model_05 <- NA
    temp1$model_05[!is.na(temp1$covariate_value_scaled)] <- predict(model_05, newdata=temp1)
    
    model_95 <- rqss(formula=form, tau = 0.95, data = temp1 %>% na.omit() )
    temp1$model_95 <- NA
    temp1$model_95[!is.na(temp1$covariate_value_scaled)] <- predict(model_95, newdata=temp1)
  })
    
  suppressWarnings({ 
    p <- temp1 %>%
          ggplot(aes(x=covariate_value %>% scale(),y=shap)) +
          geom_ribbon(aes(ymin=model_05, ymax=model_95), color="pink", fill='pink') +
          geom_line(aes(x=covariate_value_scaled, y=median_50), color="red", size=0.15) +
          #geom_point() + 
          #geom_quantile(method = "rqss", lambda = 0.1, quantiles = c(0.05, 0.95), na.rm=T, linetype=c('solid'), color="red", size=0.75,
          #              formula=form) +
          #geom_quantile(method = "rqss", lambda = 0.1, quantiles = c(0.5), na.rm=T, linetype=c('solid'), color="red", formula=form , size=0.15) +
          theme_void() + 
          geom_hline(yintercept=0, linetype="dashed", color = "blue", size=0.1) + 
          geom_vline(xintercept=0, linetype="dashed", color = "blue", size=0.1)
  })
  ggsave(filename=glue::glue("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/docs/plots/p_ablation_marginal_fx_{i}.png") ,
         plot = p , height=0.1, width=0.3)
}




treeshap_top

```


We dissagregate the role of individual features from our best performing model below in Table XXXX. Nearly a quarter of the model's weight assigned to predictions comes from a single feature, share of Trump Vote in 2020, and it is the only feature that was chosen in all 5 folds. Having Trump share below 50% has a consistent flat increase in vaccine uptake, and then share approaching and surpassing 50% leads to monotonic and near linear decline in uptake. Trump Vote share in 2016 was chosen in 4 out of 5 folds and contributes about another 10% to the model's predictions, with a similar shape as 2020 vote. Together they account for a third of the model's weights assigned to out of sample predictions. The next most impactful feature is demographic, percent share African American which accounts for about 4% of model weight. Its contribution is to reduce expected vaccine uptake for counties that are above average African American, monotonically in the share of that population.

```{r, results="asis"}

df <- 
shap_total %>% 
  full_join(folds_chosen) %>% 
  mutate(shap_percent_cumsum=cumsum(shap_percent)) %>%

  dplyr::select(variable, n, shap, shap_percent, shap_percent_cumsum) %>%
  
  mutate(variable= variable %>%
           str_replace_all("_",' ') %>% 
           str_replace_all("donaldjtrump 2020",'Trump Vote AAAA') %>%
           str_replace_all("donaldtrump 2016",'Trump Vote BBBB') %>%
           str_replace_all("[0-9]{4}",'') %>% 
           str_replace_all("AAAA",'2020') %>%
           str_replace_all("BBBB",'2016') %>%
           str_replace_all("perc$|perc |percent of |per capita |percent ",'') %>% 
           str_replace_all("percap",'') %>% 
           str_replace_all("change in people ",'Δ ') %>% 
           str_replace_all("\\(.*?\\)",' ') %>% 
           str_replace_all("--total number of adherents",' ') %>% 
           str_replace_all(" years and over",'<') %>% 
           str_replace_all(" under ",'≥') %>% 
           str_replace_all("  ",' ') %>% 
           str_replace_all(" ,",',') %>%
           trimws()
  ) %>%

  mutate(marginal_fx = glue::glue("![](./plots/p_ablation_marginal_fx_{row_number()}.png)")) %>% 
  filter(round(shap)>0)  %>%
  as_hux() %>% 
  theme_compact() %>%
  insert_row("", "", "Shap", "", "","", after = 0) %>%
  set_header_rows(1:2, TRUE) %>%  
  style_headers(bold = TRUE, text_color = "black") %>% 
  set_caption("") %>%
  merge_cells(1, 1:2) %>% 
  merge_cells(1, 3:5)  
  #merge_cells(1, 5:6) %>% 
  #merge_cells(1, 7:8) %>%
  
markdown(df)[, 6] <- TRUE
col_width(df)[1] <- 0.5
wrap(df)[1]  <- T
df[2,] <- c('Feature','Folds','Sum', '%','Cum. %','Marginal Fx.')
df %>% 
  set_right_border(row=1:nrow(df), col=1) %>%
  set_right_border(row=1:nrow(df), col=2) %>%
  set_right_border(row=1:nrow(df), col=5) %>%
  
  set_number_format(col=c(4,5), value= fmt_percent(1)) %>% 
  set_background_color(evens, everywhere, "grey80") #%>% 
  #set_background_color(odds, everywhere, "grey90") 
               

```

```{r, eval=F}

used_vars_df <- treeshap_top %>% 
  dplyr::group_by(ablation, k_smallest, variable) %>% 
    summarise(shap_variable_total= shap %>% abs() %>% sum() ) %>%
  dplyr::group_by(ablation,  k_smallest) %>% 
    mutate(shap_cluster_total=shap_variable_total %>% abs() %>% sum()) %>%
  ungroup() %>%
  #filter(shap_cluster_total==max(shap_cluster_total)) %>% 
  dplyr::arrange(ablation,shap_cluster_total %>% desc(),shap_variable_total %>% desc() ) %>%
  collect()

rhs_codebook_total_clustered <- readRDS("/mnt/8tb_a/rwd_github_private/TrumpSupportVaccinationRates/data_out/rhs_codebook_total_clustered.Rds")


top_5_vars_by_abblation <- used_vars_df %>% group_by(ablation) %>% slice_head(n = 5) %>%
  filter(shap_cluster_total==max(shap_cluster_total)) %>%
  left_join(rhs_codebook_total_clustered %>% dplyr::select(variable=variable, description  )) %>%
  mutate(description_clean = description %>%
           str_replace_all("_",' ') %>% 
           str_replace_all("donaldjtrump 2020",'Trump Vote AAAA') %>%
           str_replace_all("donaldtrump 2016",'Trump Vote BBBB') %>%
           str_replace_all("[0-9]{4}",'') %>% 
           str_replace_all("AAAA",'2020') %>%
           str_replace_all("BBBB",'2016') %>%
           str_replace_all("perc$|perc |percent of |per capita |percent ",'') %>% 
           str_replace_all("percap",'') %>% 
           str_replace_all("change in people ",'Δ ') %>% 
           str_replace_all("\\(.*?\\)",' ') %>% 
           str_replace_all("--total number of adherents",' ') %>% 
           str_replace_all(" years and over",'<') %>% 
           str_replace_all(" under ",'≥') %>% 
           str_replace_all("  ",' ') %>% 
           str_replace_all(" ,",',') %>%
           trimws()
         )
#top_5_vars_by_abblation %>% View()


#install.packages('formattable')
library(formattable)
top_5_vars_by_abblation %>% 
  mutate(shap_variable_total =  color_bar("lightgreen")(shap_variable_total %>% round())  ) %>%
  dplyr::select(ablation,k_smallest,description_clean,shap=shap_variable_total) %>%
  mutate(ablation=ablation %>% as.character()) %>%
  mutate(k_smallest=k_smallest %>% as.character()) %>%
  
  kbl(format='html',booktabs = TRUE, longtable = TRUE, escape = F, align = 'c' ) %>% #
  column_spec(3, width = "10cm" ) %>%
  column_spec(4, width = "1cm" ) %>%
  collapse_rows(columns = 1:2, valign = "top")


```



# References


